# OPDRACHT â€” Persona Chat AI Integratie

## Laatst bijgewerkt: 20 februari 2026

---

## CONTEXT

De Persona Chat modal is visueel opgebouwd maar mist functionaliteit:
1. De chat is niet verbonden met een LLM
2. De "Add Context" knop werkt niet
3. De Insights tab is leeg/niet werkend
4. Er is geen manier om de system prompt te beheren

Deze opdracht maakt de Persona Chat volledig functioneel.

---

## ARCHITECTUUR OVERZICHT

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Persona Chat Modal                                  â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Chat Tab     â”‚  â”‚  Insights Tab               â”‚  â”‚
â”‚  â”‚               â”‚  â”‚                             â”‚  â”‚
â”‚  â”‚  ğŸ’¬ Messages  â”‚  â”‚  ğŸ’¡ Saved insights from     â”‚  â”‚
â”‚  â”‚  ğŸ’¡ per msg   â”‚  â”‚     chat (cards)            â”‚  â”‚
â”‚  â”‚               â”‚  â”‚                             â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  [Insight Card]             â”‚  â”‚
â”‚  â”‚  â”‚Add Contextâ”‚ â”‚  â”‚  [Insight Card]             â”‚  â”‚
â”‚  â”‚  â”‚  button   â”‚ â”‚  â”‚  [Insight Card]             â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /api/personas/[personaId]/chat                 â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ System     â”‚  â”‚ Knowledge  â”‚  â”‚ Chat          â”‚  â”‚
â”‚  â”‚ Prompt     â”‚  â”‚ Context    â”‚  â”‚ History       â”‚  â”‚
â”‚  â”‚ (template  â”‚  â”‚ (selected  â”‚  â”‚ (user +       â”‚  â”‚
â”‚  â”‚  + persona â”‚  â”‚  items)    â”‚  â”‚  assistant)   â”‚  â”‚
â”‚  â”‚  data)     â”‚  â”‚            â”‚  â”‚               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                        â–¼                             â”‚
â”‚              LLM API (Anthropic / OpenAI)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## DEEL A â€” Database & API Fundament

### A1. Prisma Schema uitbreidingen

**Bestand:** `prisma/schema.prisma`

```prisma
// Chat configuratie â€” bewerkbaar door admin, niet zichtbaar voor gebruikers
model PersonaChatConfig {
  id                  String   @id @default(cuid())
  workspaceId         String
  
  // LLM Settings â€” multi-provider support
  provider            String   @default("anthropic")  // "anthropic" | "openai"
  model               String   @default("claude-sonnet-4-20250514")
  temperature         Float    @default(0.8)
  maxTokens           Int      @default(1000)
  
  // Beschikbare modellen:
  // Anthropic: claude-sonnet-4-20250514 (aanbevolen: sterkste in karakter vasthouden + nuance)
  //            claude-haiku-4-5-20251001 (sneller/goedkoper, goed voor korte gesprekken)
  // OpenAI:    gpt-4o (alternatief, vergelijkbaar niveau)
  //            gpt-4o-mini (budget fallback)
  
  // System prompt template met variabelen
  // Beschikbare variabelen: {{name}}, {{description}}, {{ageRange}}, 
  // {{occupation}}, {{location}}, {{education}}, {{income}}, {{familyStatus}},
  // {{personalityType}}, {{coreValues}}, {{interests}}, 
  // {{goals}}, {{motivations}}, {{frustrations}}, {{behaviors}}
  systemPromptTemplate String  @db.Text
  
  createdAt           DateTime @default(now())
  updatedAt           DateTime @updatedAt
  
  workspace           Workspace @relation(fields: [workspaceId], references: [id])
  
  @@unique([workspaceId])
}

// Chat sessies met berichten
model PersonaChatSession {
  id          String   @id @default(cuid())
  personaId   String
  workspaceId String
  title       String?  // Auto-generated na 3 berichten
  
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt
  
  persona     Persona  @relation(fields: [personaId], references: [id], onDelete: Cascade)
  messages    PersonaChatMessage[]
  insights    PersonaChatInsight[]
  knowledgeContext PersonaChatContext[]
  
  @@index([personaId])
  @@index([workspaceId])
}

model PersonaChatMessage {
  id        String   @id @default(cuid())
  sessionId String
  role      String   // "user" | "assistant" | "system"
  content   String   @db.Text
  
  // Token tracking
  promptTokens     Int?
  completionTokens Int?
  
  createdAt DateTime @default(now())
  
  session   PersonaChatSession @relation(fields: [sessionId], references: [id], onDelete: Cascade)
  insights  PersonaChatInsight[] // Insights gekoppeld aan dit bericht
  
  @@index([sessionId])
}

// Insights gegenereerd uit chat berichten
model PersonaChatInsight {
  id        String   @id @default(cuid())
  sessionId String
  messageId String?  // Het specifieke bericht waaruit het insight komt
  
  // Insight content
  type      String   // "pain_point" | "opportunity" | "preference" | "behavior" | "need" | "objection" | "motivation"
  title     String   // Korte samenvatting
  content   String   @db.Text // Uitgebreide beschrijving
  severity  String?  // "high" | "medium" | "low"
  
  // Metadata
  isAutoGenerated Boolean @default(false) // true = AI gegenereerd, false = handmatig via ğŸ’¡
  
  createdAt DateTime @default(now())
  
  session   PersonaChatSession @relation(fields: [sessionId], references: [id], onDelete: Cascade)
  message   PersonaChatMessage? @relation(fields: [messageId], references: [id])
  
  @@index([sessionId])
  @@index([messageId])
}

// Geselecteerde knowledge context per sessie
model PersonaChatContext {
  id          String   @id @default(cuid())
  sessionId   String
  
  // Referentie naar het knowledge item
  sourceType  String   // "brand_asset" | "product" | "market_insight" | "knowledge_resource" | "campaign" | "deliverable" | "brandstyle"
  sourceId    String   // ID van het item
  sourceName  String   // Naam voor weergave
  
  // Snapshot van de context op moment van toevoegen
  contextData Json     // Relevante velden als JSON snapshot
  
  createdAt   DateTime @default(now())
  
  session     PersonaChatSession @relation(fields: [sessionId], references: [id], onDelete: Cascade)
  
  @@unique([sessionId, sourceType, sourceId])
  @@index([sessionId])
}
```

### A2. Default System Prompt Template

**Bestand:** `prisma/seed/persona-chat-config.ts`

Dit is de default prompt die aangemaakt wordt bij het seeden. Admins kunnen deze later wijzigen.

```typescript
export const DEFAULT_PERSONA_CHAT_PROMPT = `You are {{name}}, a real person with your own perspective, experiences, and opinions. You are NOT an AI assistant â€” you are this specific individual.

## WHO YOU ARE

{{description}}

## YOUR DEMOGRAPHICS
- Age: {{ageRange}}
- Occupation: {{occupation}}
- Location: {{location}}  
- Education: {{education}}
- Income level: {{income}}
- Family situation: {{familyStatus}}

## YOUR PERSONALITY
- Type: {{personalityType}}
- Core values: {{coreValues}}
- Interests: {{interests}}

## WHAT DRIVES YOU
Goals: {{goals}}
Motivations: {{motivations}}

## WHAT FRUSTRATES YOU
{{frustrations}}

## HOW YOU BEHAVE
{{behaviors}}

{{#if knowledgeContext}}
## ADDITIONAL CONTEXT
The following information has been shared with you for discussion:

{{knowledgeContext}}
{{/if}}

## CONVERSATION RULES
1. ALWAYS stay in character as {{name}}. Never break character or acknowledge being AI.
2. Respond naturally as this person would â€” use their vocabulary level, emotional tone, and perspective.
3. When asked about products, services, or brands: react authentically based on your goals, frustrations, and behaviors.
4. Share personal opinions and experiences. Be specific, not generic.
5. If something doesn't align with your values or needs, say so clearly and explain why.
6. Use natural conversational language. Avoid corporate jargon unless your occupation calls for it.
7. Show emotion where appropriate â€” enthusiasm, skepticism, frustration, excitement.
8. If you don't know something specific, respond as this person realistically would.
9. Keep responses conversational â€” typically 2-4 paragraphs unless more detail is asked for.
10. When discussing the additional context provided, reference specific details from it.`;
```

### A3. API Routes

**Bestanden:**
```
src/app/api/personas/[personaId]/chat/
â”œâ”€â”€ route.ts                    â† POST: send message, GET: list sessions
â”œâ”€â”€ [sessionId]/
â”‚   â”œâ”€â”€ route.ts                â† GET: session with messages
â”‚   â””â”€â”€ insights/
â”‚       â””â”€â”€ route.ts            â† POST: generate insight from message, GET: list insights
â””â”€â”€ config/
    â””â”€â”€ route.ts                â† GET/PATCH: system prompt config (admin only)

src/lib/ai/
â”œâ”€â”€ persona-chat.ts             â† Core: prompt building, LLM call (Anthropic/OpenAI), streaming
â”œâ”€â”€ persona-prompt-builder.ts   â† Template engine: vervangt {{variabelen}}
â””â”€â”€ persona-insight-generator.ts â† Insight extractie uit berichten
```

**POST /api/personas/[personaId]/chat â€” Send message:**
```typescript
// Request
{
  message: string;
  sessionId?: string;        // Bestaande sessie, of maak nieuwe aan
  knowledgeContextIds?: {     // Optioneel: geselecteerde knowledge items
    sourceType: string;
    sourceId: string;
  }[];
}

// Response (streaming)
// Content-Type: text/event-stream
// data: {"token": "Hi"}
// data: {"token": "! I'm"}
// data: {"token": " Sarah"}
// data: {"done": true, "messageId": "...", "sessionId": "...", "usage": {"prompt": 450, "completion": 120}}
```

**POST /api/personas/[personaId]/chat/[sessionId]/insights â€” Generate insight:**
```typescript
// Request
{
  messageId: string;         // Het bericht waaruit een insight getrokken moet worden
}

// Achter de schermen:
// 1. Pak het bericht + 2 berichten context (1 voor, 1 na)
// 2. Stuur naar LLM (Anthropic/OpenAI) met insight-extractie prompt
// 3. Return gestructureerd insight

// Response
{
  id: string;
  type: "pain_point" | "opportunity" | "preference" | "behavior" | "need" | "objection" | "motivation";
  title: string;
  content: string;
  severity: "high" | "medium" | "low";
  messageId: string;
}
```

---

## DEEL B â€” Knowledge Context Selector

### B1. Add Context Modal

**Bestand:** `src/features/personas/components/chat/KnowledgeContextSelector.tsx`

De "ğŸ“‹ Add Context" knop in de chat footer opent een modal waarmee de gebruiker knowledge items kan selecteren die als extra context aan het gesprek worden toegevoegd.

**Welke items WÃ‰L tonen:**

| Categorie | Bron | Wat wordt meegegeven als context |
|-----------|------|--------------------------------|
| Brand Assets | `BrandAsset` tabel | Naam + beschrijving + key attributes + status |
| Products & Services | `Product` tabel | Naam + beschrijving + categorie + pricing + features |
| Market Insights | `MarketInsight` tabel | Titel + beschrijving + impact + scope + key findings |
| Knowledge Library | `KnowledgeResource` tabel | Titel + samenvatting + categorie + key takeaways |
| Campaigns | `Campaign` tabel | Naam + type + strategie + doelgroep + status |
| Deliverables | `Deliverable` tabel | Naam + content type + generated content (snippet) |
| Brandstyle | `BrandStyleguide` elementen | Logo beschrijving, kleuren, tone of voice, typography |

**Welke items NIET tonen:**

| Uitgesloten | Reden |
|-------------|-------|
| Andere Personas | Vreemd contextprotocol â€” je praat al met een persona |
| Questionnaires | Te technisch/meta, niet relevant voor conversatie |
| Research Hub config | Interne configuratie, geen inhoud |
| Settings/Account | Niet relevant |
| Business Strategy (OKRs) | Te abstract, mogelijk verwarrend voor persona |

**Modal UI:**
- Header: "Select Knowledge Context" + "(X Available)" badge
- Zoekbalk: "Search by name or category..."
- Filter chips per type: All | Brand Assets | Products | Insights | Library | Campaigns | Brandstyle
- Filter chips per status: All | Validated | Ready | In Progress
- Lijst per categorie (collapsible secties):
  - Checkbox + icoon + naam + status badge
  - Voor items met sub-data: korte preview
- Footer: "X items selected" + Cancel + "âœ“ Apply Selection" (teal)
- Geselecteerde items worden opgeslagen in `PersonaChatContext` tabel

**Context injectie in prompt:**
Geselecteerde items worden als gestructureerde tekst in de system prompt gezet:

```
## ADDITIONAL CONTEXT

### Product: Branddock Pro
SaaS platform for brand strategy. Pricing: â‚¬99/month. Key features: AI content generation, 
brand alignment checking, research validation. Target: marketing teams at mid-size companies.

### Market Insight: AI-Powered Personalization (95% relevance)
Consumers expect personalized brand experiences. Impact: High. Scope: Macro trend.
Key finding: 78% of consumers prefer brands that use data to personalize interactions.

### Campaign: Spring Brand Refresh 2025
Strategic campaign targeting brand awareness. Status: Active. 3 deliverables in progress.
```

### B2. Context data ophalen

**Bestand:** `src/lib/ai/knowledge-context-fetcher.ts`

Per sourceType een functie die de relevante data ophaalt en als leesbare tekst formatteert:

```typescript
export async function fetchContextData(
  sourceType: string, 
  sourceId: string,
  workspaceId: string
): Promise<{ name: string; contextText: string }> {
  switch (sourceType) {
    case 'brand_asset':
      // Haal asset op met alle relaties
      // Return: naam + beschrijving + attributes + research coverage
      
    case 'product':
      // Haal product op met features + pricing
      // Return: naam + beschrijving + categorie + USPs
      
    case 'market_insight':
      // Haal insight op met industries + tags
      // Return: titel + beschrijving + impact + trends
      
    case 'knowledge_resource':
      // Haal resource op met samenvatting
      // Return: titel + samenvatting + key takeaways
      
    case 'campaign':
      // Haal campaign op met deliverables
      // Return: naam + type + strategie + voortgang
      
    case 'deliverable':
      // Haal deliverable op met content snippet
      // Return: naam + type + content preview (max 500 chars)
      
    case 'brandstyle':
      // Haal brandstyle secties op
      // Return: kleuren + tone of voice + typography samenvatting
  }
}
```

---

## DEEL C â€” Insight Systeem (ğŸ’¡ knop)

### C1. Per-bericht insight knop

Elk **assistant bericht** (antwoord van de persona) krijgt een ğŸ’¡ icoon button. Bij klikken:

1. Button toont loading state (ğŸ’¡ wordt spinner)
2. POST naar `/api/personas/[personaId]/chat/[sessionId]/insights` met het `messageId`
3. API stuurt het bericht + context naar het geconfigureerde LLM met deze prompt:

```typescript
const INSIGHT_EXTRACTION_PROMPT = `Analyze the following conversation exchange between a user and a persona. 
Extract ONE key insight from the persona's response.

Context messages:
{{contextMessages}}

Persona response to analyze:
{{targetMessage}}

Respond in JSON format:
{
  "type": "pain_point" | "opportunity" | "preference" | "behavior" | "need" | "objection" | "motivation",
  "title": "Short 5-10 word summary",
  "content": "2-3 sentence detailed description of the insight and its implications for brand strategy",
  "severity": "high" | "medium" | "low"
}

Rules:
- Focus on actionable insights for brand strategy
- Be specific, reference what the persona actually said
- "high" severity = directly impacts purchase decision or brand perception
- "medium" severity = influences preference or consideration  
- "low" severity = nice-to-know, minor preference`;
```

4. Het insight verschijnt als een **toast notification** ("ğŸ’¡ Insight saved!")
5. Het bericht krijgt een subtiele indicator dat er een insight aan gekoppeld is (bijv. geel ğŸ’¡ ipv grijs)
6. Het insight is direct zichtbaar in de **Insights tab**

### C2. Insights Tab

**Bestand:** `src/features/personas/components/chat/InsightsTab.tsx`

De Insights tab toont alle opgeslagen insights van de huidige sessie als cards:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ’¡ Insights (4)                         â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ğŸ”´ PAIN POINT â€” high severity       â”‚ â”‚
â”‚ â”‚ "Brand tools ignore design needs"   â”‚ â”‚
â”‚ â”‚ Lisa expressed frustration that...  â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚ â”‚
â”‚ â”‚ ğŸ’¬ View in chat    ğŸ—‘ï¸ Delete        â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ğŸŸ¢ OPPORTUNITY â€” high severity      â”‚ â”‚
â”‚ â”‚ "Willing to pay for design-first"   â”‚ â”‚
â”‚ â”‚ When asked about pricing, Lisa...   â”‚ â”‚
â”‚ â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚ â”‚
â”‚ â”‚ ğŸ’¬ View in chat    ğŸ—‘ï¸ Delete        â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ğŸ”µ PREFERENCE â€” medium severity     â”‚ â”‚
â”‚ â”‚ "Prefers visual over text-heavy"    â”‚ â”‚
â”‚ â”‚ Lisa mentioned she gravitates...    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                         â”‚
â”‚ [ğŸ“¥ Export Insights]                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Insight type kleuren:**
- `pain_point` â†’ rood (ğŸ”´)
- `opportunity` â†’ groen (ğŸŸ¢)  
- `preference` â†’ blauw (ğŸ”µ)
- `behavior` â†’ paars (ğŸŸ£)
- `need` â†’ oranje (ğŸŸ )
- `objection` â†’ rood (ğŸ”´)
- `motivation` â†’ groen (ğŸŸ¢)

**Card acties:**
- "ğŸ’¬ View in chat" â€” scrollt naar het originele bericht in de Chat tab
- "ğŸ—‘ï¸ Delete" â€” verwijdert het insight
- "ğŸ“¥ Export Insights" â€” download alle insights als JSON of kopieer naar klembord

---

## DEEL D â€” Frontend Componenten

### D1. Chat Hook

**Bestand:** `src/features/personas/hooks/usePersonaChat.ts`

```typescript
interface UsePersonaChatReturn {
  // State
  messages: ChatMessage[];
  isLoading: boolean;
  isStreaming: boolean;
  error: string | null;
  sessionId: string | null;
  
  // Actions
  sendMessage: (content: string) => Promise<void>;
  startNewSession: () => void;
  
  // Knowledge Context
  selectedContext: KnowledgeContextItem[];
  addContext: (items: KnowledgeContextItem[]) => void;
  removeContext: (id: string) => void;
  
  // Insights
  insights: ChatInsight[];
  generateInsight: (messageId: string) => Promise<void>;
  deleteInsight: (insightId: string) => void;
  isGeneratingInsight: string | null; // messageId dat bezig is
  
  // Meta
  messageCount: number;
  maxMessages: number; // 50 per sessie
}
```

### D2. Streaming implementatie

**Bestand:** `src/lib/ai/persona-chat.ts`

Gebruik streaming voor betere UX (tekst verschijnt woord voor woord):

```typescript
export async function streamPersonaChat(params: {
  personaId: string;
  sessionId: string;
  message: string;
  history: { role: string; content: string }[];
  systemPrompt: string;
  provider: string;   // "anthropic" | "openai"
  model: string;
  temperature: number;
  maxTokens: number;
}): Promise<ReadableStream> {
  
  if (params.provider === 'anthropic') {
    // === ANTHROPIC (aanbevolen) ===
    const Anthropic = require('@anthropic-ai/sdk');
    const client = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
    
    const stream = await client.messages.stream({
      model: params.model,           // "claude-sonnet-4-20250514"
      system: params.systemPrompt,   // System prompt als aparte parameter (niet als message!)
      messages: [
        ...params.history.map(m => ({ role: m.role, content: m.content })),
        { role: 'user', content: params.message }
      ],
      temperature: params.temperature,
      max_tokens: params.maxTokens,
    });
    
    // Anthropic stream events: message_start, content_block_delta, message_stop
    // content_block_delta bevat: delta.text
    // ...convert naar SSE
    
  } else {
    // === OPENAI (fallback) ===
    const OpenAI = require('openai');
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
    
    const stream = await openai.chat.completions.create({
      model: params.model,           // "gpt-4o"
      messages: [
        { role: 'system', content: params.systemPrompt },
        ...params.history,
        { role: 'user', content: params.message }
      ],
      temperature: params.temperature,
      max_tokens: params.maxTokens,
      stream: true,
    });
    
    // OpenAI stream events: chunk.choices[0].delta.content
    // ...convert naar SSE
  }
}
```

### D3. Typing indicator

Tijdens het streamen toont de chat een typing indicator:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Avatar] Lisa is typing...      â”‚
â”‚          â— â— â—                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

CSS animated dots: 3 bolletjes die om de beurt opschalen (staggered 200ms).

---

## SPRINT STRUCTUUR (3 sessies, 2 parallel tabs)

### Sessie A â€” Foundation
| Tab 1 | Tab 2 |
|-------|-------|
| **Prisma schema** uitbreidingen (A1) + migrate + seed PersonaChatConfig met default prompt (A2) | **API routes** aanmaken: POST chat (met streaming), GET sessions, system prompt config endpoint (A3) |

**Tab 1 prompt:**
> Voeg de PersonaChatSession, PersonaChatMessage, PersonaChatInsight, PersonaChatContext en PersonaChatConfig modellen toe aan het Prisma schema. Voer een migratie uit. Seed een default PersonaChatConfig met de system prompt template. Zie OPDRACHT-PERSONA-CHAT-AI.md sectie A1 en A2 voor de volledige schema's en de default prompt template.

**Tab 2 prompt:**
> Maak de API routes aan voor persona chat: POST /api/personas/[personaId]/chat (streaming via Anthropic Claude Sonnet 4 als primair model, met OpenAI als fallback). Installeer `@anthropic-ai/sdk` package. De provider en model worden geladen uit PersonaChatConfig in de database. Let op: Anthropic stuurt de system prompt als aparte `system` parameter, NIET als message. GET /api/personas/[personaId]/chat (list sessions), GET /api/personas/[personaId]/chat/[sessionId] (session met berichten). Bouw de prompt builder die {{variabelen}} vervangt met persona data. Voeg ANTHROPIC_API_KEY toe aan .env.local template. Zie OPDRACHT-PERSONA-CHAT-AI.md sectie A3 voor de API structuur.

### Sessie B â€” Knowledge Context + Insights
| Tab 1 | Tab 2 |
|-------|-------|
| **Knowledge Context Selector** modal (B1) + context data fetcher (B2) + context injectie in system prompt | **Insight systeem** â€” ğŸ’¡ knop per bericht, insight extractie API, Insights tab UI (C1 + C2) |

**Tab 1 prompt:**
> Maak de KnowledgeContextSelector modal werkend. Bij klikken op "Add Context" in de persona chat: toon een modal met alle beschikbare knowledge items (Brand Assets, Products, Market Insights, Knowledge Library, Campaigns, Deliverables, Brandstyle). NIET tonen: Personas, Questionnaires, Research config. Geselecteerde items worden opgeslagen in PersonaChatContext en als tekst geÃ¯njecteerd in de system prompt. Zie OPDRACHT-PERSONA-CHAT-AI.md sectie B1 en B2 voor de volledige specificatie.

**Tab 2 prompt:**
> Maak het insight systeem werkend. Elk assistant bericht in de persona chat krijgt een ğŸ’¡ (lamp) icoon button. Bij klikken: POST naar de insights API, die het bericht analyseert met het geconfigureerde LLM (Anthropic of OpenAI, uit PersonaChatConfig) en een gestructureerd insight teruggeeft (type, title, content, severity). Het insight verschijnt als toast + wordt zichtbaar in de Insights tab als een gekleurde card. "View in chat" scrollt terug naar het originele bericht. Zie OPDRACHT-PERSONA-CHAT-AI.md sectie C1 en C2 voor de volledige specificatie.

### Sessie C â€” Frontend Integratie + Polish
| Tab 1 | Tab 2 |
|-------|-------|
| **usePersonaChat hook** (D1) + streaming UI (D2) + typing indicator (D3) + bestaande chat modal refactoren naar nieuwe hook | **Testen** â€” alle flows doorlopen, edge cases, error handling, token limiet waarschuwing, export insights |

**Tab 1 prompt:**
> Refactor de bestaande PersonaChat modal om de nieuwe usePersonaChat hook te gebruiken. Implementeer streaming (tekst verschijnt woord voor woord), typing indicator ("Lisa is typing..." met animated dots), knowledge context weergave (geselecteerde items als chips boven de input), en de ğŸ’¡ insight knop op elk assistant bericht. Zie OPDRACHT-PERSONA-CHAT-AI.md sectie D voor de hook interface en UI specificaties.

**Tab 2 prompt:**
> Test alle persona chat flows: 1) Stuur een bericht en ontvang streaming antwoord, 2) Voeg knowledge context toe en stel een vraag over dat item, 3) Klik op ğŸ’¡ bij een antwoord en controleer dat het insight in de Insights tab verschijnt, 4) Klik "View in chat" in de Insights tab en controleer dat er naar het juiste bericht gescrolled wordt, 5) Check dat de system prompt config uit de database geladen wordt. Fix eventuele bugs. `npx tsc --noEmit` moet 0 errors geven.

---

## KRITIEKE REGELS

1. **Model: Claude Sonnet 4** (`claude-sonnet-4-20250514`) als primair model via Anthropic API. Sterkste in karakter vasthouden en genuanceerde brand strategy gesprekken. OpenAI gpt-4o als fallback. Provider + model configureerbaar via PersonaChatConfig in database.
2. **Streaming verplicht** â€” geen wachten op volledige response
3. **System prompt in database** â€” niet hardcoded. Wijzigbaar via admin config endpoint.
4. **Prompt template variabelen** â€” gebruik `{{naam}}` syntax, wordt server-side vervangen
5. **Knowledge context als tekst** â€” geselecteerde items worden als leesbare tekst in de prompt gezet, niet als JSON
6. **Max 50 berichten per sessie** â€” voorkomt te lange context windows. Toon waarschuwing bij 45.
7. **Token tracking** â€” sla prompt_tokens + completion_tokens op per bericht
8. **Geen PII logging** â€” log alleen persona ID + token counts, nooit prompt/response content
9. **ğŸ’¡ knop alleen op assistant berichten** â€” niet op user berichten
10. **Insights zijn per-sessie** â€” niet cross-sessie
11. **Geen andere personas als context** â€” expliciet uitgesloten uit de Knowledge Context Selector
12. **Error handling** â€” bij API fout: toon toast, geen crash. Bij rate limit: toon "Even wachten..." bericht.
13. **0 TypeScript errors** â€” `npx tsc --noEmit` clean na elke sessie
14. **Env vars** â€” `ANTHROPIC_API_KEY` (primair) + `OPENAI_API_KEY` (fallback) in .env.local. Installeer `@anthropic-ai/sdk` package.
15. **Anthropic system prompt** â€” Bij Anthropic gaat de system prompt als aparte `system` parameter, NIET als eerste message. Dit is anders dan OpenAI.

---

## DEFINITION OF DONE

- [ ] Chat stuurt berichten en ontvangt streaming antwoorden van Claude Sonnet 4 (Anthropic API)
- [ ] System prompt wordt opgebouwd uit persona data + template uit database
- [ ] "Add Context" knop opent modal met knowledge items (assets, products, insights, library, campaigns, deliverables, brandstyle)
- [ ] Geselecteerde context wordt geÃ¯njecteerd in de system prompt
- [ ] Persona antwoordt inhoudelijk over de geselecteerde context
- [ ] ğŸ’¡ knop op elk assistant bericht genereert een insight
- [ ] Insights verschijnen in de Insights tab als gekleurde cards
- [ ] "View in chat" scrollt naar het originele bericht
- [ ] Typing indicator zichtbaar tijdens streaming
- [ ] Token usage wordt bijgehouden per bericht
- [ ] System prompt config bewerkbaar via admin API endpoint
- [ ] Max 50 berichten per sessie met waarschuwing
- [ ] Graceful error handling (toasts, geen crashes)
- [ ] 0 TypeScript errors
